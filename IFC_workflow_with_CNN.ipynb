{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input:\n",
    "\n",
    "filelist = ['/home/minh-doan/Leukemia_DeepLearning/LK209pres/blasts.cif',\n",
    "            '/home/minh-doan/Leukemia_DeepLearning/LK209pres/normal.cif']\n",
    "\n",
    "# Parts of file names should contain annotations of the classes, e.g. normal_file1, normal_file2, disease_1,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User's settings:\n",
    "\n",
    "image_size = 28 # Choose the size of the bound box around objects\n",
    "classes = [\"normal\",\"blast\"] # classes names should be in at least 1 file name\n",
    "wanted_channel = [0,2,5,6,11] # IFC typically have 12 channels indexed from 0 : 0,1,2,3....11\n",
    "split = 0.8 # Set the split ratio 80% data for training, 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "import pickle\n",
    "import os\n",
    "import os.path\n",
    "import skimage.io\n",
    "import skimage.util.montage\n",
    "import bioformats\n",
    "import bioformats.formatreader\n",
    "import javabridge\n",
    "import math\n",
    "from PIL import Image\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase heap space for javabridge to deal with big .cif file\n",
    "javabridge.start_vm(class_path=bioformats.JARS, max_heap_size='8G')\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To make every bound box have the same size\n",
    "\n",
    "def __pad_or_crop(image, image_size):\n",
    "    bigger = max(image.shape[0], image.shape[1], image_size)\n",
    "\n",
    "    pad_x = float(bigger - image.shape[0])\n",
    "    pad_y = float(bigger - image.shape[1])\n",
    "\n",
    "    pad_width_x = (int(math.floor(pad_x / 2)), int(math.ceil(pad_x / 2)))\n",
    "    pad_width_y = (int(math.floor(pad_y / 2)), int(math.ceil(pad_y / 2)))\n",
    "    sample = image[int(image.shape[0]/2)-4:int(image.shape[0]/2)+4, :8]\n",
    "\n",
    "    std = numpy.std(sample)\n",
    "\n",
    "    mean = numpy.mean(sample)\n",
    "\n",
    "    def normal(vector, pad_width, iaxis, kwargs):\n",
    "        vector[:pad_width[0]] = numpy.random.normal(mean, std, vector[:pad_width[0]].shape)\n",
    "        vector[-pad_width[1]:] = numpy.random.normal(mean, std, vector[-pad_width[1]:].shape)\n",
    "        return vector\n",
    "\n",
    "    if (image_size > image.shape[0]) & (image_size > image.shape[1]):\n",
    "        return numpy.pad(image, (pad_width_x, pad_width_y), normal)\n",
    "    else:\n",
    "        if bigger > image.shape[1]:\n",
    "            temp_image = numpy.pad(image, (pad_width_y), normal)\n",
    "        else:\n",
    "            if bigger > image.shape[0]:\n",
    "                temp_image = numpy.pad(image, (pad_width_x), normal)\n",
    "            else:\n",
    "                temp_image = image\n",
    "        return temp_image[int((temp_image.shape[0] - image_size)/2):int((temp_image.shape[0] + image_size)/2),int((temp_image.shape[1] - image_size)/2):int((temp_image.shape[1] + image_size)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make tensor and corresponding labels\n",
    "\n",
    "multichannel_tensors = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(filelist)):\n",
    "    single_channel_tensors = []\n",
    "    filename = filelist[i]\n",
    "    reader = bioformats.formatreader.get_image_reader(\"tmp\", path=filename)\n",
    "    image_count = javabridge.call(reader.metadata, \"getImageCount\", \"()I\")\n",
    "    channel_count = javabridge.call(reader.metadata, \"getChannelCount\", \"(I)I\", 0)\n",
    "    output = filename.replace(\".cif\", \"\")\n",
    "\n",
    "    for j in range(len(wanted_channel)):\n",
    "\n",
    "        images = [reader.read(c=wanted_channel[j], series=image) for image in range(image_count)[::2]]\n",
    "\n",
    "        cropped_images_this_channel = numpy.expand_dims([__pad_or_crop(image, image_size) for image in images], axis =3)\n",
    "\n",
    "        single_channel_tensors.append(cropped_images_this_channel)\n",
    "\n",
    "\n",
    "    #transform nested single_channel_tensor to multi_channel_tensor\n",
    "    multichannel_tensor = numpy.concatenate((single_channel_tensors), axis = 3)\n",
    "\n",
    "    multichannel_tensors.append(multichannel_tensor)\n",
    "\n",
    "    label = numpy.zeros((multichannel_tensor.shape[0],len(classes)))\n",
    "    for k in range(len(classes)):\n",
    "        if classes[k] in filelist[i]:\n",
    "            label[:multichannel_tensor.shape[0],k]=1\n",
    "            labels.append(label)\n",
    "\n",
    "T = numpy.concatenate((multichannel_tensors))\n",
    "L = numpy.concatenate((labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/minh-doan/Leukemia_DeepLearning/LK209pres/T.sav saved !\n"
     ]
    }
   ],
   "source": [
    "# filename = 'T' + '.sav'\n",
    "# pickle.dump(T, open(filename, 'wb'))\n",
    "# print(filename, \"saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/minh-doan/Leukemia_DeepLearning/LK209pres/L.sav saved !\n"
     ]
    }
   ],
   "source": [
    "# filename = 'L' + '.sav'\n",
    "# pickle.dump(L, open(filename, 'wb'))\n",
    "# print(filename, \"saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data set\n",
    "\n",
    "index = numpy.arange(L.shape[0])\n",
    "numpy.random.shuffle(index)\n",
    "\n",
    "Training_index = index[:int(L.shape[0]*split)]\n",
    "Training_set_temp = T[Training_index,:,:,:]\n",
    "Training_labels_set_temp = L[Training_index,:]\n",
    "Training_set_temp_index = numpy.arange(Training_set_temp.shape[0])\n",
    "\n",
    "Testing_index = index[:-int(L.shape[0]*split)]\n",
    "Testing_set = T[Testing_index,:,:,:]\n",
    "Testing_labels_set = L[Testing_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders for tensorflow\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, image_size,image_size,len(wanted_channel)]) # Last number is number of color channels\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, len(classes)]) # Last number is number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kernels, weights, biases, settings for Deep learning\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# shape of [5, 5, len(wanted_channel), 32]. the third is the number of input channels (colors)\n",
    "W_conv1 = weight_variable([5, 5, len(wanted_channel), 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# First convolutional layer\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Densely Connected Layer\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, len(classes)]) # Last number is number of classes\n",
    "b_fc2 = bias_variable([len(classes)]) # Number is number of classes\n",
    "\n",
    "h_fc2 = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "y_conv=tf.nn.softmax(h_fc2)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "# y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 1.0) : 2920\n",
      "(1.0, 0.0) : 2165\n"
     ]
    }
   ],
   "source": [
    "# Check for imbalance:\n",
    "\n",
    "from collections import Counter\n",
    "tuple_L = [tuple(element) for element in L]\n",
    "\n",
    "freq = Counter(tuple_L)\n",
    "\n",
    "import collections\n",
    "\n",
    "size = []\n",
    "for l in list(set(tuple_L)):\n",
    "    print( '%s : %d' % (l, freq[l]))\n",
    "    size.append(freq[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = int(Training_labels_set_temp.shape[0]/1000)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.3\n",
      "step 500, training accuracy 0.7\n",
      "step 1000, training accuracy 1\n",
      "step 1500, training accuracy 1\n",
      "step 2000, training accuracy 0.966667\n",
      "step 2500, training accuracy 1\n",
      "step 3000, training accuracy 1\n",
      "step 3500, training accuracy 1\n",
      "test accuracy 0.999017\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "finalRepresentations = []\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    numpy.random.shuffle(Training_set_temp_index)\n",
    "    batchIndex = Training_set_temp_index[0:30]\n",
    "\n",
    "    Training_set = Training_set_temp[batchIndex,:,:,:]\n",
    "    Training_labels_set = Training_labels_set_temp[batchIndex,:]\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:Training_set, y_: Training_labels_set, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        finalRepresentations.append(h_fc2.eval(session=sess, feed_dict={x:Testing_set, keep_prob:1.0}))\n",
    "        # current representation of the network. Represent how the network \"see\" the data.\n",
    "\n",
    "    train_step.run(feed_dict={x: Training_set, y_: Training_labels_set, keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(session=sess,feed_dict={x: Testing_set, y_: Testing_labels_set, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you wish to see the evolution of accuracy from early stage to late stage of DeepLearning filter\n",
    "# tSNE_weights_testing_set = []\n",
    "\n",
    "# for i in finalRepresentations:\n",
    "#     tsne = TSNE(perplexity=50, n_components=2, init='pca', n_iter=5000)\n",
    "#     plot_only = Testing_set.shape[0]\n",
    "#     lowDWeights = tsne.fit_transform(i[0:plot_only,:])\n",
    "#     tSNE_weights_testing_set.append(lowDWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save metadata for Tensorboard\n",
    "\n",
    "metadata = os.path.join('metadata.tsv')\n",
    "\n",
    "images_tb = tf.Variable(finalRepresentations[-1], name='images')\n",
    "            \n",
    "def save_metadata(file):\n",
    "    with open(file, 'w') as f:\n",
    "        for i in range(Testing_labels_set.shape[0]):\n",
    "            c = numpy.nonzero(Testing_labels_set[::1])[1:][0][i]\n",
    "            f.write('{}\\n'.format(c))\n",
    "            \n",
    "save_metadata('metadata.tsv')\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([images_tb])\n",
    "\n",
    "    sess.run(images_tb.initializer)\n",
    "    saver.save(sess, os.path.join('images_tb.ckpt'))\n",
    "\n",
    "    config = projector.ProjectorConfig()\n",
    "    # One can add multiple embeddings.\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = images_tb.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    embedding.metadata_path = metadata\n",
    "    # Saves a config file that TensorBoard will read during startup.\n",
    "    projector.visualize_embeddings(tf.summary.FileWriter('.'), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Close Tensorflow session, save memory !\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Have a careful check in this output : \"projector_config.pbtxt\"\n",
    "# \"/path/to/logdir/metadata.tsv\" has to be specified, CANNOT be relative path \"./metadata.tsv\", nor \"~/metadata.tsv\"\n",
    "\n",
    "# Type command in terminal: tensorboard --logdir=\"/path/to/logdir\"\n",
    "\n",
    "# Next, open web-browser, connect to http://localhost:6006."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
